{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "gesture_templates = {\n",
    "    \"OneFinger\": [\"./vids/OneFinger1.mp4\", \"./vids/OneFinger2.mp4\", \"./vids/OneFinger3.mp4\"],\n",
    "    \"TwoFingers\": [\"./vids/TwoFingers1.mp4\", \"./vids/TwoFingers2.mp4\", \"./vids/TwoFingers3.mp4\"],\n",
    "    \"ThreeFingers\": [\"./vids/ThreeFingers1.mp4\", \"./vids/ThreeFingers2.mp4\", \"./vids/ThreeFingers3.mp4\", \"./vids/ThreeFingers4.mp4\", \"./vids/ThreeFingers5.mp4\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_gesture_points(video_files, gesture_type):\n",
    "    points = []\n",
    "    for video_path in video_files:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = holistic.process(image)\n",
    "\n",
    "                if results.right_hand_landmarks or results.left_hand_landmarks:\n",
    "                    hand_landmarks = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "                    index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                    middle_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                    ring_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "                    pinky_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                    if gesture_type == \"OneFinger\":\n",
    "                        if (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                            middle_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                            ring_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                            pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                            points.append(Point(index_tip.x, index_tip.y, 1))\n",
    "\n",
    "                    elif gesture_type == \"TwoFingers\":\n",
    "                        if (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                            middle_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                            ring_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                            pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                            points.extend([Point(index_tip.x, index_tip.y, 1), Point(middle_tip.x, middle_tip.y, 1)])\n",
    "\n",
    "                    elif gesture_type == \"ThreeFingers\":\n",
    "                        if (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                            middle_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                            ring_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                            pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                            points.extend([Point(index_tip.x, index_tip.y, 1), Point(middle_tip.x, middle_tip.y, 1), Point(ring_tip.x, ring_tip.y, 1)])\n",
    "\n",
    "                cv2.imshow(\"Training Gesture\", cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for gesture_type, video_paths in gesture_templates.items():\n",
    "    points = capture_gesture_points(video_paths, gesture_type)\n",
    "    if points:\n",
    "        templates.append(Template(gesture_type, points))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to gesture_templates.pkl\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'gesture_templates.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(templates, model_file)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_filename = 'gesture_templates.pkl'\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    templates = pickle.load(model_file)\n",
    "    \n",
    "\n",
    "recognizer = Recognizer(templates)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_gestures_real_time():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(image)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            detected_gesture = \"No gesture\"\n",
    "            if results.right_hand_landmarks or results.left_hand_landmarks:\n",
    "                hand_landmarks = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "                points = []\n",
    "\n",
    "                # Get fingertip landmarks\n",
    "                index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                middle_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                ring_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "                pinky_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                # Draw circles on specific fingertip points\n",
    "                def draw_circle(landmark, color):\n",
    "                    cx, cy = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "                    cv2.circle(image, (cx, cy), 10, color, -1)\n",
    "\n",
    "                # Detect gestures and show points for each gesture\n",
    "                if (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                    middle_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                    ring_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                    pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                    points.append(Point(index_tip.x, index_tip.y, 1))\n",
    "                    detected_gesture = \"One Finger Up\"\n",
    "                    draw_circle(index_tip, (0, 255, 0))  # Green circle for One Finger Up\n",
    "\n",
    "                elif (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                      middle_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                      ring_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                      pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                    points.extend([Point(index_tip.x, index_tip.y, 1), Point(middle_tip.x, middle_tip.y, 1)])\n",
    "                    detected_gesture = \"Two Fingers Up\"\n",
    "                    draw_circle(index_tip, (0, 0, 255))     # Red circle for index finger\n",
    "                    draw_circle(middle_tip, (255, 0, 0))   # Blue circle for middle finger\n",
    "\n",
    "                elif (index_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP].y and\n",
    "                      middle_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_MCP].y and\n",
    "                      ring_tip.y < hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_MCP].y and\n",
    "                      pinky_tip.y > hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_MCP].y):\n",
    "                    points.extend([Point(index_tip.x, index_tip.y, 1), Point(middle_tip.x, middle_tip.y, 1), Point(ring_tip.x, ring_tip.y, 1)])\n",
    "                    detected_gesture = \"Three Fingers Up\"\n",
    "                    draw_circle(index_tip, (255, 255, 0))  # Cyan for index\n",
    "                    draw_circle(middle_tip, (0, 255, 255)) # Yellow for middle\n",
    "                    draw_circle(ring_tip, (255, 0, 255))   # Magenta for ring\n",
    "\n",
    "            cv2.putText(image, f\"Gesture: {detected_gesture}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "           \n",
    "            cv2.imshow(\"Gesture Detection\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_gestures_real_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
